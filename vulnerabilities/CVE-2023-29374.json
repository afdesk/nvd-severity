{
  "Description": "In LangChain through 0.0.131, the LLMMathChain chain allows prompt injection attacks that can execute arbitrary code via the Python exec method.",
  "Severity": "UNKNOWN",
  "Score": 0.0
}